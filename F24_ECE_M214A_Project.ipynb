{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-0v2HEH8a6p"
      },
      "source": [
        "\n",
        "<span style=\"color:green\"><h1>UCLA, Fall 2024 </span> <span style=\"color:yellow\"> ****</h1></span>\n",
        "<span style=\"color:blue\"><h2>Professor Abeer Alwan, alwan@ee.ucla.edu</span> <span style=\"color:yellow\"> ****</h2></span>\n",
        "<span style=\"color:blue\"><h3>Dept. of Electrical Engineering EE214A: Digital Speech Processing</span> <span style=\"color:yellow\"> ****</span>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUGt3c3glZcm"
      },
      "source": [
        "# ECE M214A Project: Speaker Region Identification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U45DldLRvjGB"
      },
      "source": [
        "In this project, we'll train a machine learning algorithm to classify speakers by regional dialect.  We will use speech samples from the Corpus of Regional African American Language (CORAAL - https://oraal.github.io/coraal) with speakers each belonging to one of six different US cities: 1) Rochester, NY (ROC), 2) Lower East Side, Manhattan, NY (LES), 3) Washington DC (DCB), 4) Princeville, NC (PRV), 5) Valdosta, GA (VLD) or 6) Detroit, MI (DTA)\n",
        "\n",
        "The project files can be downloaded from [this link](https://ucla.box.com/s/mohh4fnmgj3vekui8i8n28i02odleaop)\n",
        "\n",
        "To do this, we will first extract features from the audio files and then train a classifier to predict the city of origin of the utterance's speaker.  The goal is to extract a feature that contains useful information about regional dialect characteristics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZGgwhT7lsNZ"
      },
      "source": [
        "##1. Setting up the data directories and Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSI8N_Imwiwz"
      },
      "source": [
        "Store a copy of the project files in your google drive.\n",
        "\n",
        "Make sure that the 'project_data' folder is stored in the top level of your google drive. Otherwise, you will need to change the corresponding paths in the remainder of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srmiFaC9xSw4"
      },
      "source": [
        "Mount your google drive. This will give this notebook read/write access to data stored in your google drive.  You can either do this in the file browser on the left side of this notebook or by running the code snippet below.\n",
        "\n",
        "It is recommended that you use your UCLA google account for this project, as it has more storage than a standard google account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3m33QfY8a6s"
      },
      "source": [
        "# <span style=\"color:orange\"> Required Common Imports - Packages/Modules/Libraries <span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erX0556X8a6s",
        "outputId": "9ef14546-e369-4c96-d610-f99746e1d5f3"
      },
      "outputs": [],
      "source": [
        "%pip install torchaudio\n",
        "%pip install --upgrade pip\n",
        "%pip install librosa\n",
        "%pip install xgboost\n",
        "%pip install tqdm\n",
        "%pip install panda\n",
        "%pip install shap\n",
        "%pip install matplotlib\n",
        "%pip install opensmile\n",
        "%pip install ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <span style=\"color:orange\"> Print Environment Information <span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "def is_colab():\n",
        "  return 'google.colab' in sys.modules\n",
        "\n",
        "if is_colab():\n",
        "  print(\"Running in Google Colab\")\n",
        "  !python --version\n",
        "else:\n",
        "  print(\"Not running in Google Colab\")\n",
        "  %pip --version\n",
        "  !python3 --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <span style=\"color:yellow\"> **** </span><span style=\"color:red\"> Setting up environment based on Colab Vs Laptop </span> <span style=\"color:yellow\"> ****</span>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4zO9lTk8a6u",
        "outputId": "2ac3db0b-59b9-4cdf-b57f-96a35742aa4d"
      },
      "outputs": [],
      "source": [
        "if is_colab():\n",
        "  print(\"*******  Running in Google Colab Environment *******\")\n",
        "  \n",
        "  from google.colab import userdata\n",
        "  gh_pat = userdata.get('gh_pat')\n",
        "  gh_username = userdata.get('gh_username')\n",
        "\n",
        "\n",
        "  # We have to 'mount' google drive to this notebook. This will allow us to access files from google drive here.\n",
        "  # You will be asked permission to grant access to your drive. Click 'Connect to Google Drive' when prompted and select the appropriate google account. Click on Continue untill window closes.\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  import sys, os\n",
        "  parent_dir = os.path.dirname(os.path.realpath('drive/MyDrive/ece_m214/'))\n",
        "  print (parent_dir)\n",
        "\n",
        "  # To get one directory up from the current file\n",
        "  project_dir = os.path.abspath(os.path.join(parent_dir, 'ece_m214/final_project'))\n",
        "\n",
        "  sys.path.insert(0,project_dir)\n",
        "\n",
        "  print ('Parent Directory Path:', parent_dir)\n",
        "  print ('Project Path:', project_dir)\n",
        "\n",
        "else:\n",
        "\n",
        "  print(\"*********  Running in Non - Google Colab Environment *********\")\n",
        "  \n",
        "  import sys, os\n",
        "\n",
        "  parent_dir = os.path.dirname(os.path.realpath('/Users/parthakundu/GitHub/my_ucla_grad_projects/'))\n",
        "  print (parent_dir)\n",
        "\n",
        "  # To get one directory up from the current file\n",
        "  # project_dir = os.path.abspath(os.path.join(parent_dir, 'drive/MyDrive/ece_m214/final_project/'))\n",
        "  project_dir = os.path.abspath(os.path.join(parent_dir, \"./my_ucla_grad_projects/ucla-ece-m214a-project-sri/\"))\n",
        "\n",
        "  sys.path.insert(0,project_dir)\n",
        "\n",
        "  print ('Parent Directory Path:', parent_dir)\n",
        "  print ('Project Path:', project_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLcsUULg8a6u"
      },
      "source": [
        "# <span style=\"color:red\"> ***** </span><span style=\"color:blue\"> Execute all the cells from this point for all environment</span> <span style=\"color:green\"> ***** </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder1_path = project_dir + \"/dataFrame\"\n",
        "folder2_path = project_dir + \"/images\"\n",
        "folder3_path = project_dir + \"/project_data\"\n",
        "folder4_path = project_dir + \"/zip_files\"\n",
        "\n",
        "os.makedirs(folder1_path, exist_ok=True)\n",
        "os.makedirs(folder2_path, exist_ok=True)\n",
        "os.makedirs(folder3_path, exist_ok=True)\n",
        "os.makedirs(folder4_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip4HXEA28a6u"
      },
      "source": [
        "# <span style=\"color:red\"> ***** </span><span style=\"color:orange\">Loading Initial/Given Dataset</span> <span style=\"color:green\"> ***** </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7kara018a6u"
      },
      "outputs": [],
      "source": [
        "# #  Uncomment following line of codes and execute if you need unzip the provided package with dataset for the project.\n",
        "\n",
        "# import zipfile\n",
        "\n",
        "# with zipfile.ZipFile(parent_dir + '/ece_m214/final_project/F24 ECE M214A Project.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall(parent_dir + '/ece_m214/final_project/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUKk6flWvYVB"
      },
      "source": [
        "To run this project on your local system, replace the corresponding file paths to the locations of the project files on your local machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hon860bcmLDD"
      },
      "source": [
        "## 2. Getting familiar with the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaEIHyQByAiy"
      },
      "source": [
        "\n",
        "Let's take a moment to understand the data.  The original CORAAL dataset consists of speakersfrom one of seven cities split into 8 components.  The audio files are names with the convention: DCB_se1_ag1_f_03.  Here, DCB is the city code, se1 denotes the socioeconomic group of the speaker, ag1 denotes the age group of the speaker, f denotes female, and 03 denotes the participant number.  These unique combinations of identifiers mark the speaker.  \n",
        "\n",
        "The dataset has been preprocessed to only include audio segments greater than 5 seconds in length. Those segments are numbered with the appending tag _{seg_number} for each segment.\n",
        "\n",
        "You can also try listening to any segment like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "NAiO3g1e9oN7",
        "outputId": "608ca73d-2263-4ebe-e505-b26ece00c9c6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "sr = 44100\n",
        "\n",
        "Audio(filename= project_dir + \"/project_data/train/DCB_se1_ag2_m_01_1_11.wav\", rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XvoR_iOmexS"
      },
      "source": [
        "The original dataset has also been split into a train and test set. The test set has been further split, with a portion corrupted with the addition of noise:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "taM2RJCGnVS1",
        "outputId": "dc749a83-9a94-4bea-9185-f99b69374572"
      },
      "outputs": [],
      "source": [
        "sr = 44100\n",
        "\n",
        "Audio(filename= project_dir + \"/project_data/test_clean/ROC_se0_ag2_f_01_1_396.wav\", rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "iUVXpyyLGxds",
        "outputId": "8995d951-e383-4298-d33f-d67862e80a26"
      },
      "outputs": [],
      "source": [
        "sr = 44100\n",
        "\n",
        "Audio(filename= project_dir + \"/project_data/test_noisy/VLD_se0_ag4_m_02_1_64.wav\", rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uu12stenzcx"
      },
      "source": [
        "## 3. Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QpW8VRs9t_c"
      },
      "source": [
        "As a baseline, we will be using the average mfcc value over time from the Librosa Python library. Your job will be to choose better features to improve performance on both the clean and noisy data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNEtHr-TapYg"
      },
      "source": [
        "We first define a pair of functions to create features and labels for our classification model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8nOljY9x9Bo"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def extract_feature(audio_file, n_mfcc=13):\n",
        "\n",
        "  '''\n",
        "  Function to extract features from a single audio file given its path\n",
        "  Modify this function to extract your own custom features\n",
        "  '''\n",
        "\n",
        "  audio,fs = torchaudio.load(audio_file)\n",
        "  audio = audio.numpy().reshape(-1)\n",
        "\n",
        "  # replace the following features with your own\n",
        "  mfccs = librosa.feature.mfcc(y=audio, sr=fs, n_mfcc=n_mfcc)\n",
        "  feat_out = np.mean(mfccs,axis=1)\n",
        "\n",
        "  return feat_out\n",
        "\n",
        "\n",
        "def get_label(file_name):\n",
        "  '''\n",
        "  Function to retrieve output labels from filenames\n",
        "  '''\n",
        "  if 'ROC' in file_name:\n",
        "    label=0\n",
        "  elif 'LES' in file_name:\n",
        "    label=1\n",
        "  elif 'DCB' in file_name:\n",
        "    label=2\n",
        "  elif 'PRV' in file_name:\n",
        "    label=3\n",
        "  elif 'VLD' in file_name:\n",
        "    label=4\n",
        "  elif 'DTA' in file_name:\n",
        "    label=5\n",
        "  else:\n",
        "    raise ValueError('invalid file name')\n",
        "  return label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAe_LnvKbCO_"
      },
      "source": [
        "Let us now call these functions to extract the features and labels from the train directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XdmLAGFYkaG",
        "outputId": "e081d128-dbb9-4f22-898f-49d3686cc3bc"
      },
      "outputs": [],
      "source": [
        "\n",
        "#First we obtain the list of all files in the train directory\n",
        "train_files = glob(project_dir + '/project_data/train/*.wav')\n",
        "\n",
        "#Let's sort it so that we're all using the same file list order\n",
        "#and you can continue processing the features from a given file if it stops\n",
        "#partway through running\n",
        "train_files.sort()\n",
        "\n",
        "train_feat=[]\n",
        "train_label=[]\n",
        "\n",
        "for wav in tqdm(train_files):\n",
        "\n",
        "  train_feat.append(extract_feature(wav))\n",
        "  train_label.append(get_label(wav))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCG2eFFL8a6v",
        "outputId": "1a77fa03-8add-4123-89f2-f78e2a357856"
      },
      "outputs": [],
      "source": [
        "\n",
        "print (\"Length of train_feat:\",len(train_feat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkyzBSo-bwOo",
        "outputId": "ee3f2ea8-b164-4598-d5af-c3d71928710f"
      },
      "outputs": [],
      "source": [
        "#Now we obtain the list of all files in the test_clean directory\n",
        "test_clean_files = glob(project_dir + '/project_data/test_clean/*.wav')\n",
        "\n",
        "#Similar to above, we sort the files\n",
        "test_clean_files.sort()\n",
        "\n",
        "test_clean_feat=[]\n",
        "test_clean_label=[]\n",
        "\n",
        "for wav in tqdm(test_clean_files):\n",
        "\n",
        "  test_clean_feat.append(extract_feature(wav))\n",
        "  test_clean_label.append(get_label(wav))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgsZpLQB8a6w",
        "outputId": "1c269899-ab66-4e4b-f3fd-c2e61bac0285"
      },
      "outputs": [],
      "source": [
        "print (\"Length of test_clean_feat:\",len(test_clean_feat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP6-pNDQbxLU",
        "outputId": "aaa2b399-827b-4017-ca25-e1e1f2b5dc4f"
      },
      "outputs": [],
      "source": [
        "#Finally we obtain the list of all files in the test_noisy directory\n",
        "test_noisy_files = glob(project_dir + '/project_data/test_noisy/*.wav')\n",
        "\n",
        "#Similar to above, we sort the files\n",
        "test_noisy_files.sort()\n",
        "\n",
        "test_noisy_feat=[]\n",
        "test_noisy_label=[]\n",
        "\n",
        "for wav in tqdm(test_noisy_files):\n",
        "\n",
        "  test_noisy_feat.append(extract_feature(wav))\n",
        "  test_noisy_label.append(get_label(wav))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgkW0weB8a6w",
        "outputId": "0c473868-726c-401c-b2a2-b0d1f88ef7ac"
      },
      "outputs": [],
      "source": [
        "print (\"Length of test_noisy_feat:\",len(test_noisy_feat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw2ju2S9oUD-"
      },
      "source": [
        "## 4. Model Training and Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssNxb69kMSCg"
      },
      "source": [
        "Now we'll train the backend system to predict the regions from the input features.  We'll use an xgboosted decision tree for this.  An advantage of this model is that we can also parse the decision tree and measure the impact of different features in the end result for explainability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdlSdywtJ0jm",
        "outputId": "ebdee3d7-0dd7-4ddb-a153-d236c0c00d49"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Format input data\n",
        "\n",
        "#Edit this variable to create a list that contains your feature names\n",
        "feat_names=['mfcc_' +str(n) for n in range(len(train_feat[0]))]\n",
        "\n",
        "train_feat_df = pd.DataFrame(data=np.stack(train_feat), columns=feat_names)\n",
        "y_train=np.stack(train_label)\n",
        "\n",
        "\n",
        "test_clean_feat_df = pd.DataFrame(data=np.stack(test_clean_feat), columns=feat_names)\n",
        "y_test_clean=np.stack(test_clean_label)\n",
        "\n",
        "\n",
        "test_noisy_feat_df = pd.DataFrame(data=np.stack(test_noisy_feat), columns=feat_names)\n",
        "y_test_noisy=np.stack(test_noisy_label)\n",
        "\n",
        "\n",
        "#you could just pass in the matrix of features to xgboost\n",
        "#but it looks prettier in the shap explainer if you format it\n",
        "#as a dataframe.\n",
        "\n",
        "\n",
        "model = xgboost.XGBClassifier()\n",
        "model.fit(train_feat_df,y_train)\n",
        "\n",
        "print(\"Train Clean Acc =\", np.sum(y_train==model.predict(train_feat_df))/len(y_train))\n",
        "\n",
        "print(\"Test Clean Acc =\", np.sum(y_test_clean==model.predict(test_clean_feat_df))/len(y_test_clean))\n",
        "\n",
        "print(\"Test Noisy Acc =\", np.sum(y_test_noisy==model.predict(test_noisy_feat_df))/len(y_test_noisy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU1Zv35-Xdfh"
      },
      "source": [
        "To save a dataframe of features, uncomment and run the following block of code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVCxaJuqXj8S"
      },
      "outputs": [],
      "source": [
        "# train_feat_df.to_csv(project_dir + '/dataFrame/current_features.csv')\n",
        "train_feat_df.to_csv(project_dir + '/dataFrame/myfeat_train.csv')\n",
        "test_clean_feat_df.to_csv(project_dir + '/dataFrame/myfeat_test_clean.csv')\n",
        "test_noisy_feat_df.to_csv(project_dir + '/dataFrame/myfeat_test_noisy.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS7zsBisXwgt"
      },
      "source": [
        "To Load a preexisting dataframe of features (saved from a previous notebook), run the following cell and then train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzXTGihBX8Py"
      },
      "outputs": [],
      "source": [
        "train_feat_df = pd.read_csv(project_dir + '/dataFrame/myfeat_train.csv')\n",
        "test_clean_feat_df = pd.read_csv(project_dir + '/dataFrame/myfeat_test_clean.csv')\n",
        "test_noisy_feat_df = pd.read_csv(project_dir + '/dataFrame/myfeat_test_noisy.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-E5w5FsoeLK"
      },
      "source": [
        "## 5. Interpreting Results and Explainability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x11o8qaNfSYT"
      },
      "source": [
        "To see the impact different features have on the model, we create a plot of the feature importances. The features are listed top to bottom in order of how important they were to the decision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7aXxyyBeLkE"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# Explain the model's predictions using SHAP by computing SHAP values\n",
        "explainer = shap.Explainer(model)\n",
        "shap_values = explainer.shap_values(train_feat_df)\n",
        "\n",
        "#Convert the shap values for each class to a single list\n",
        "shap_as_list=[]\n",
        "# print (shap_as_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "29g7zdtq8a60",
        "outputId": "57d858e2-5585-4a52-bc4b-5a55b7f6671b"
      },
      "outputs": [],
      "source": [
        "for i in range(6):\n",
        "    print (shap_values[i])\n",
        "    shap_as_list.append(shap_values[:,:,i])\n",
        "\n",
        "# Plot the SHAP values\n",
        "shap.summary_plot(shap_as_list, train_feat_df, plot_type=\"bar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlzXmcA-fd7x"
      },
      "source": [
        "And we can see a confusion matrix of the mispredictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "e5xFg3P2fqj_",
        "outputId": "5f00e7e6-dcaa-4764-b1a7-c700d40a0319"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "confusion_matrix_clean = metrics.confusion_matrix(y_test_clean, model.predict(test_clean_feat_df))\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_clean, display_labels = ['ROC','LES','DCB','PRV','VLD', 'DTA'])\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "K5S3VgD4TXQe",
        "outputId": "d4717545-22ae-4fb0-d1ca-975f7364fab1"
      },
      "outputs": [],
      "source": [
        "\n",
        "confusion_matrix_noisy = metrics.confusion_matrix(y_test_noisy, model.predict(test_noisy_feat_df))\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_noisy, display_labels = ['ROC','LES','DCB','PRV','VLD', 'DTA'])\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
